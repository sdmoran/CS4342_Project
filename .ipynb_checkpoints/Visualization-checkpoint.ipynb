{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "data = pd.read_csv('./data/TrainData_Labeled.csv')\n",
    "\n",
    "# Performs classification with given model and data.\n",
    "# @param model: the SKLearn model to use for predictions\n",
    "# @param data: The data to use for training and testing\n",
    "def classify(model, data):\n",
    "    # Convert data from Pandas DataFrame to np array for X and y\n",
    "    X = np.asarray(data)[:, :11]\n",
    "    y = np.asarray(data)[:, 11]\n",
    "\n",
    "    # Partition data into train and test samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, )\n",
    "    \n",
    "    # Classify with given model and print report\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    # print(classification_report(y_test, pred))\n",
    "    scores = cross_val_score(model, X_test, y_test, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\\n\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap correlations between different variables.\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(data=data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above figure, lighter colors mean a higher correlation. Label correlates most highly to alcohol content, then to sulphates and citric acid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not quite a useful visualization, because it does not show the data scattered by class - just the data points. Unfortunately there seems to be an error in Seaborn that is raised when trying to color datapoints based on label... that's not super helpful\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify with Stochastic Gradient Descent & print report\n",
    "sgd = SGDClassifier(penalty=None)\n",
    "print(\"Stochastic Gradient Descent classifier results:\")\n",
    "classify(sgd, data)\n",
    "\n",
    "# Classify with K Nearest Neighbors & print report\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "print(\"K Nearest Neighbors classifier results:\")\n",
    "classify(knn, data)\n",
    "\n",
    "# Classify with Random Forest Classifier & print report\n",
    "rfc = RandomForestClassifier(n_estimators=250)\n",
    "print(\"Random Forest classifier results:\")\n",
    "classify(rfc, data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After running the 3 classifiers above a number of times, the Random Forest classifier typically does best with ~55-65% accuracy, followed by the KNN classifier with ~40-55% accuracy, then finally Stochastic Gradient Descent, with ~30-50% accuracy. Random Forest also consistently does the best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
